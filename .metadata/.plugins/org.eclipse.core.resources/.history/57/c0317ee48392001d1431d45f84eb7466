import org.jsoup.Connection;
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;

import lombok.extern.slf4j.Slf4j;

import java.io.IOException;

@Slf4j
private static void crawling() {
    String URL = "https://sports.news.naver.com/wfootball/index.nhn";; // 원하는 url
    Document doc;

    try {
        doc = Jsoup.connect(URL)
                .userAgent("Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.152 Safari/537.36")
                .get(); // 원하는 url에서 전체 구조를 받아온다
        Elements elem = doc
                .select("div.home_news");

        // 확인
        elem.forEach(System.out::println);


    } catch (IOException e) {
        e.printStackTrace();
    }

}